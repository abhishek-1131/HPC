{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T07:20:42.550618Z",
     "start_time": "2020-07-16T07:20:28.275049Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import os\n",
    "from joblib import load, dump\n",
    "import shutil\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,)),])\n",
    "trainset = datasets.MNIST('./data', download=True, train=True, transform=transform)\n",
    "testset = datasets.MNIST('./data', download=True, train=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = len(trainset))\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = len(testset))\n",
    "trainset_array1 = next(iter(trainloader))[0].numpy()\n",
    "testset_array1 = next(iter(testloader))[0].numpy()\n",
    "\n",
    "trainset_labels_array1 = next(iter(trainloader))[1].numpy()\n",
    "testset_labels_array1 = next(iter(testloader))[1].numpy()\n",
    "\n",
    "trainset_array = trainset_array1.reshape(60000,784)\n",
    "testset_array = testset_array1.reshape(10000,784)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T07:17:55.603169Z",
     "start_time": "2020-07-16T07:17:55.540488Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_folder_test = tempfile.mkdtemp()\n",
    "filename_test = os.path.join(temp_folder_test, 'test.mmap')\n",
    "if os.path.exists(filename_test): os.unlink(filename_test)\n",
    "_ = dump(testset_array, filename_test)\n",
    "test_memmap = load(filename_test, mmap_mode='r+')\n",
    "\n",
    "temp_folder_train = tempfile.mkdtemp()\n",
    "filename_train = os.path.join(temp_folder_train, 'train.mmap')\n",
    "if os.path.exists(filename_train): os.unlink(filename_train)\n",
    "_ = dump(trainset_array, filename_train)\n",
    "train_memmap = load(filename_train, mmap_mode='r+')\n",
    "\n",
    "del testset_array\n",
    "del trainset_array\n",
    "import gc\n",
    "_ = gc.collect()\n",
    "\n",
    "test_memmap_small = test_memmap[:512]\n",
    "train_memmap_small = train_memmap[:512]\n",
    "\n",
    "test_memmap_final = np.asarray(test_memmap_small)\n",
    "train_memmap_final = np.asarray(train_memmap_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T07:20:42.554437Z",
     "start_time": "2020-07-16T07:20:42.551756Z"
    }
   },
   "outputs": [],
   "source": [
    "testset_array2 = testset_array[:512]\n",
    "trainset_array2 = trainset_array[:512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T07:22:33.420549Z",
     "start_time": "2020-07-16T07:22:33.418062Z"
    }
   },
   "outputs": [],
   "source": [
    "def case3(a):\n",
    "    list1 = []\n",
    "    for y in testset_array2:\n",
    "        val = sum((a-y)**2)\n",
    "        list1.append(val)\n",
    "    return list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T07:19:10.369551Z",
     "start_time": "2020-07-16T07:18:30.758470Z"
    }
   },
   "outputs": [],
   "source": [
    "################\n",
    "# non-parallel #\n",
    "################\n",
    "\n",
    "final_list01 = []\n",
    "start = datetime.now()\n",
    "\n",
    "for x in trainset_array2:\n",
    "    final_list01.append(case3(x))\n",
    "final_list01 = np.asarray(final_list01)\n",
    "final02 = [list(x) for x in zip(*final_list01)] \n",
    "l01 = []\n",
    "i=0\n",
    "for x in final02:\n",
    "    y = np.argmin(x)\n",
    "    l01.append(trainset_labels_array1[y])\n",
    "    i+=1\n",
    "\n",
    "end = datetime.now()\n",
    "time_taken = end - start\n",
    "print('Time: ',time_taken) \n",
    "print(len(l01))\n",
    "# try:\n",
    "#     shutil.rmtree(temp_folder_test)\n",
    "#     shutil.rmtree(temp_folder_train)\n",
    "# except OSError:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T07:11:32.032002Z",
     "start_time": "2020-07-16T07:11:32.023284Z"
    }
   },
   "outputs": [],
   "source": [
    "l01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T07:24:08.360946Z",
     "start_time": "2020-07-16T07:23:55.630948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0:00:12.725726\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "final_list = Parallel(n_jobs=8,backend='multiprocessing',batch_size=64)(delayed(case3)(x) for x in trainset_array2)\n",
    "# final_list = np.asarray(final_list)\n",
    "final2 = [list(x) for x in zip(*final_list)] \n",
    "l1 = []\n",
    "i=0\n",
    "for x in final2:\n",
    "    y = np.argmin(x)\n",
    "    l1.append(trainset_labels_array1[y])\n",
    "    i+=1\n",
    "\n",
    "end = datetime.now()\n",
    "time_taken = end - start\n",
    "print('Time: ',time_taken) \n",
    "print(len(l1))\n",
    "# try:\n",
    "#     shutil.rmtree(temp_folder_test)\n",
    "#     shutil.rmtree(temp_folder_train)\n",
    "# except OSError:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T05:17:40.311195Z",
     "start_time": "2020-07-15T05:17:40.303050Z"
    }
   },
   "outputs": [],
   "source": [
    "l2 = []\n",
    "j = 0\n",
    "for j in range(0,512):\n",
    "    l2.append(testset_labels_array1[j])\n",
    "l2= np.asarray(l2)\n",
    "l2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T05:17:40.881014Z",
     "start_time": "2020-07-15T05:17:40.877157Z"
    }
   },
   "outputs": [],
   "source": [
    "j = 0\n",
    "for x in range(0,512):\n",
    "    if l1[x] == l2[x]:\n",
    "        j += 1\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T05:17:45.415467Z",
     "start_time": "2020-07-15T05:17:45.412805Z"
    }
   },
   "outputs": [],
   "source": [
    "403/512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T05:18:04.287787Z",
     "start_time": "2020-07-15T05:18:04.284367Z"
    }
   },
   "outputs": [],
   "source": [
    "dist_eg1 = final2[0]\n",
    "print(np.min(dist_eg1))\n",
    "minimum = np.argmin(dist_eg1)\n",
    "print(trainset_labels_array1[minimum])\n",
    "print(testset_labels_array1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
